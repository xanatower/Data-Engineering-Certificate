A data store, or data repository, is a general
term used to refer to data that has been collected, organized, and isolated so that it can be
used for business operations or mined for reporting and data analysis. A repository can be a database, data warehouse,
data mart, big data store, or a data lake. A well-designed data repository is essential
for building a system that is scalable and capable of performing during high workloads. In this video, we will look at some of the
primary considerations for designing a data store, such as: The type of data you want to store Volume of data Intended use of data Storage considerations And Privacy, security, and governance needs of
your organization. There are multiple types of databases and
selecting the right one is a crucial part of designing. A database is essentially a collection of
data designed for the input, storage, search and retrieval, and modification of data. Depending on the type of data, databases can
be categorized in two primary ways – relational and non-relational. Relational databases, or RDBMSes, are best
used for structured data, which has a well-defined schema and can be organized into a tabular
format. Non-relational databases, or NoSQL, are best
for semi-structured and unstructured data, that is, schema-less and free-form data. Non-relational databases, based on the type
of data and how you want to query the data, are of four different types—key-value, document,
column, and graph-based. If you're looking to run complex search queries
and multi-operation transactions, for example, a document-based database may not be the best
option for you. Like you would not opt for a graph-based database
if you need to process high-volume transactions because graph-based databases are not optimized
for large-volume analytics queries. Another important consideration that goes
into the design of a data store is the volume, or scale, of data. When you require to store large volumes of
raw data in its native format, straight from its source, a data lake would be the appropriate
choice for you. With a data lake, you can store both relational
and non-relational data at scale without defining the data's structure and schema. Or when you're dealing with Big Data, that
is data that is not only high-volume but also high-velocity, of diverse types, and needs
distributed processing for fast analytics, then a big data repository would be an option
you would explore. Big data stores split large files across multiple
computers allowing parallel access to them. Computations run in parallel on each node
where data is stored. How you intend to use the data you are collecting
is also an important consideration for the choice and design of a data store. The number of transactions, frequency of updates,
type of operations performed on the data, response time, and backup and recovery requirements
all need to be provisioned for in the design of a data store. Whether you need to use the data store for
recording high-volume transactional data or executing complex queries for analytical purposes,
your processing and storage needs will differ. Transactional systems, that is systems used
for capturing high-volume transactions, need to be designed for high-speed read, write,
and update operations. Analytical systems, on the other hand, need
complex queries to be applied to large amounts of historical data aggregated from transactional
systems. They need faster response times to complex
queries. Schema design, indexing, and partitioning
strategies have a big role to play in performance of systems based on how data is getting used. The intended use of data also drives scalability
as a design consideration. Scalability of a data store is its capability
to handle growth in the amount of data, workloads, and users. Normalization of the database is another important
consideration at the design stage. Normalization is the process of efficiently
organizing data in a database. Done right, it helps in the optimal use of
storage space, makes database maintenance easier, and provides faster access to data. Normalization is important for systems that
handle transactional data. But for systems designed for handling analytical
queries, normalization can lead to performance issues. Now we'll look at some key design considerations
from the perspective of storage. These are Performance, Availability, Integrity,
and Recoverability of Data. Performance parameters include throughput
and latency. That is, the rate at which information can
be read from and written to the storage and the time it takes to access a specific location
in storage. Availability - Your storage solution must
enable you to access your data when you need it, without exception. There should be no downtime. Integrity - Your data must be safe from corruption,
loss, and outside attack. And Recoverability - Your storage solution should
ensure that you can recover your data in the event of failures and natural disasters. A secure data strategy is a layered approach. It includes access control, multizone encryption,
data management, and monitoring systems. Regulations such as GDPR, CCPA, and HIPAA
restrict the ownership, use, and management of personal and sensitive data. Data needs to be made available through controlled
data flow and data management by using multiple data protection techniques. This is an important part of a data store
design. Strategies for data privacy, security, and
governance regulations need to be a of a data store's design from the start. Done at a later stage it results in patchwork. In this video, we learned about some of the
considerations that guide the design of a data store.